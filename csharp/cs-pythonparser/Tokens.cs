// Generated by JavaCC 21 Parser Generator. Do not edit.
// ReSharper disable InconsistentNaming
namespace org.parsers.python {
    using System;
    using System.Collections.Generic;
    using System.Diagnostics;

    public enum TokenType {
        EOF,
        SPACE,
        CONTINUE_LINE,
        COMMENT,
        NEWLINE,
        ASSIGN,
        AT,
        COLON,
        COMMA,
        EQ,
        LBRACE,
        RBRACE,
        LBRACKET,
        RBRACKET,
        LPAREN,
        RPAREN,
        SEMICOLON,
        STAR,
        STAR_STAR,
        MINUSASSIGN,
        PLUSASSIGN,
        STARASSIGN,
        ATASSIGN,
        SLASHASSIGN,
        REMASSIGN,
        ANDASSIGN,
        ORASSIGN,
        XORASSIGN,
        LSHIFTASSIGN,
        RSHIFTASSIGN,
        STARSTARASSIGN,
        SLASHSLASHASSIGN,
        BIT_AND,
        BIT_OR,
        XOR,
        TILDE,
        COLONEQUALS,
        DOT,
        ELLIPSIS,
        LE,
        GE,
        NE,
        GT,
        LT,
        MINUS,
        PLUS,
        SLASH,
        PERCENT,
        LSHIFT,
        RSHIFT,
        HOOK,
        RARROW,
        AND,
        AS,
        _ASSERT,
        ASYNC,
        AWAIT,
        BREAK,
        CASE,
        CLASS,
        CONTINUE,
        DEF,
        DEL,
        EXCEPT,
        FINALLY,
        FOR,
        FROM,
        GLOBAL,
        IF,
        IN,
        IS,
        ELIF,
        ELSE,
        FALSE,
        IMPORT,
        LAMBDA,
        MATCH,
        NONLOCAL,
        NONE,
        NOT,
        OR,
        PASS,
        PEG_PARSER,
        RAISE,
        RETURN,
        TRUE,
        TRY,
        WHILE,
        WITH,
        YIELD,
        DECNUMBER,
        BADDECNUMBER,
        HEXNUMBER,
        OCTNUMBER,
        BINNUMBER,
        FLOAT,
        COMPLEX,
        STRING_LITERAL,
        NAME,
        BADNAME,
        _TOKEN_100,
        INDENT,
        DEDENT,
        INVALID
    }

    public enum LexicalState {
     PYTHON
    }

    public interface Node {
        void Open() {}
        void Close() {}
        Lexer TokenSource { get; set; }
        Node Parent { get; set; }
        int ChildCount { get; }
        Node GetChild(int i);
        void SetChild(int i, Node n);
        void AddChild(int i, Node n);
        void AddChild(Node n);
        void RemoveChild(int i);
        void ClearChildren();

        // default implementations

        string InputSource { get {
            Lexer ts = TokenSource;

            return (ts == null) ? "input" : ts.InputSource;
        } }

        int BeginOffset { get; set; }
        int EndOffset { get; set; }

        int BeginLine {
            get {
                return (TokenSource == null) ? 0 : TokenSource.GetLineFromOffset(BeginOffset);
            }
        }

        int EndLine {
            get {
                return (TokenSource == null) ? 0 : TokenSource.GetLineFromOffset(EndOffset - 1);
            }
        }

        int BeginColumn {
            get {
                return (TokenSource == null) ? 0 : TokenSource.GetCodePointColumnFromOffset(BeginOffset);
            }
        }

        int EndColumn {
            get {
                return (TokenSource == null) ? 0 : TokenSource.GetCodePointColumnFromOffset(EndOffset - 1);
            }
        }

        bool IsUnparsed { get => false; }

        bool HasChildNodes { get { return ChildCount > 0; } }

        int IndexOf(Node child) {
            for (int i = 0; i < ChildCount; i++) {
                if (child == GetChild(i)) {
                    return i;
                }
            }
            return -1;
        }

        Node FirstChild {
            get {
                return (ChildCount > 0) ? GetChild(0) : null;
            }
        }

        Node LastChild {
            get {
                int n = ChildCount;
                return (n > 0) ? GetChild(n - 1) : null;
            }
        }

        Node Root {
            get {
                Node n = this;
                while(n.Parent != null) {
                    n = n.Parent;
                }
                return n;
            }
        }

        ListAdapter<Node> Children {
            get {
                ListAdapter<Node> result = new ListAdapter<Node>();

                for (int i = 0; i < ChildCount; i++) {
                    result.Add(GetChild(i));
                }
                return result;
            }
        }

        bool RemoveChild(Node n) {
            int i = IndexOf(n);
            if (i < 0) {
                return false;
            }
            RemoveChild(i);
            return true;
        }

        bool ReplaceChld(Node current, Node replacement) {
            int i = IndexOf(current);
            if (i < 0) {
                return false;
            }
            SetChild(i, replacement);
            return true;
        }

        bool PrependChild(Node where, Node inserted) {
            int i = IndexOf(where);
            if (i < 0) {
                return false;
            }
            AddChild(i, inserted);
            return true;
        }

        bool AppendChild(Node where, Node inserted) {
            int i = IndexOf(where);
            if (i < 0) {
                return false;
            }
            AddChild(i + 1, inserted);
            return true;
        }

        T FirstChildOfType<T>(System.Type t) where T : Node {
            var result = default(T);

            for (int i = 0; i < ChildCount; i++) {
                Node child = GetChild(i);
                if (t.IsInstanceOfType(child)) {
                    result = (T) child;
                    break;
                }
            }
            return result;
        }

        T FirstChildOfType<T>(System.Type t, Predicate<T> pred) where T : Node {
            var result = default(T);

            for (int i = 0; i < ChildCount; i++) {
                Node child = GetChild(i);
                if (t.IsInstanceOfType(child)) {
                    T c = (T) child;
                    if (pred(c)) {
                        result = c;
                        break;
                    }
                }
            }
            return result;
        }

        void CopyLocationInfo(Node start, Node end = null) {
            TokenSource = start.TokenSource;
            BeginOffset = start.BeginOffset;
            EndOffset = start.EndOffset;
            if (end != null) {
                if (TokenSource == null) {
                    TokenSource = end.TokenSource;
                }
                EndOffset = end.EndOffset;
            }
        }

        void Replace(Node toBeReplaced) {
            CopyLocationInfo(toBeReplaced);
            Node parent = toBeReplaced.Parent;
            if (parent != null) {
                int index = parent.IndexOf(toBeReplaced);
                parent.SetChild(index, this);
            }
        }

        Token FirstDescendantOfType(TokenType tt) {
            for (int i = 0; i < ChildCount; i++) {
                Node child = GetChild(i);
                Token tok;

                if (child is Token) {
                    tok = (Token) child;
                    if (tt == tok.Type) {
                        return tok;
                    }
                }
                else {
                    tok = child.FirstDescendantOfType(tt);
                    if (tok != null) {
                        return tok;
                    }
                }
            }
            return null;
        }

        Token FirstChildOfType(TokenType tt) {
            for (int i = 0; i < ChildCount; i++) {
                Node child = GetChild(i);
                if (child is Token) {
                    Token tok = (Token) child;
                    if (tt == tok.Type) {
                        return tok;
                    }
                }
            }
            return null;
        }

        ListAdapter<T> ChildrenOfType<T>(System.Type t) where T : Node {
            var result = new ListAdapter<T>();

            for (int i = 0; i < ChildCount; i++) {
                Node child = GetChild(i);
                if (t.IsInstanceOfType(child)) {
                    result.Add((T) child);
                }
            }
            return result;
        }

        ListAdapter<T> DescendantsOfType<T>(System.Type t) where T : Node {
            var result = new ListAdapter<T>();

            for (int i = 0; i < ChildCount; i++) {
                Node child = GetChild(i);
                if (t.IsInstanceOfType(child)) {
                    result.Add((T) child);
                }
                result.AddRange(child.DescendantsOfType<T>(t));
            }
            return result;
        }

        ListAdapter<T> Descendants<T>(System.Type t, Predicate<T> predicate) where T : Node {
            var result = new ListAdapter<T>();

            for (int i = 0; i < ChildCount; i++) {
                Node child = GetChild(i);
                if (t.IsInstanceOfType(child)) {
                    T c = (T) child;
                    if ((predicate == null) || predicate(c)) {
                        result.Add(c);
                    }
                }
                result.AddRange(child.Descendants<T>(t, predicate));
            }
            return result;
        }

        internal ListAdapter<Token> GetRealTokens() {
            return Descendants<Token>(typeof(Token), t => !t.IsUnparsed);
        }

        //
        // Return the very first token that is part of this node.
        // It may be an unparsed (i.e. special) token.
        //
        public Token FirstToken {
            get {
                var first = FirstChild;
                if (first == null) {
                    return null;
                }
                if (first is Token) {
                    var tok = first as Token;
                    while ((tok.PreviousCachedToken != null) && tok.PreviousCachedToken.IsUnparsed) {
                        tok = tok.PreviousCachedToken;
                    }
                    return tok;
                }
                return first.FirstToken;
            }
        }

        public Token LastToken {
            get {
                var last = LastChild;
                if (last == null) {
                    return null;
                }
                if (last is Token) {
                    return last as Token;
                }
                return last.LastToken;
            }
        }

    }

    public class BaseNode : Node {
        public Node Parent { get; set; }
        public int BeginOffset { get; set; }
        public int EndOffset { get; set; }

        // TODO us default implementations in interface
        public int BeginLine {
            get {
                return (TokenSource == null) ? 0 : TokenSource.GetLineFromOffset(BeginOffset);
            }
        }

        public int EndLine {
            get {
                return (TokenSource == null) ? 0 : TokenSource.GetLineFromOffset(EndOffset - 1);
            }
        }

        public int BeginColumn {
            get {
                return (TokenSource == null) ? 0 : TokenSource.GetCodePointColumnFromOffset(BeginOffset);
            }
        }

        public int EndColumn {
            get {
                return (TokenSource == null) ? 0 : TokenSource.GetCodePointColumnFromOffset(EndOffset - 1);
            }
        }
        
        public T FirstChildOfType<T>(System.Type t) where T : Node {
            var result = default(T);

            for (int i = 0; i < ChildCount; i++) {
                Node child = GetChild(i);
                if (t.IsInstanceOfType(child)) {
                    result = (T) child;
                    break;
                }
            }
            return result;
        }

        public ListAdapter<T> ChildrenOfType<T>(System.Type t) where T : Node {
            var result = new ListAdapter<T>();

            for (int i = 0; i < ChildCount; i++) {
                Node child = GetChild(i);
                if (t.IsInstanceOfType(child)) {
                    result.Add((T) child);
                }
            }
            return result;
        }

        internal Lexer tokenSource;
        protected ListAdapter<Node> children { get; private set; } = new ListAdapter<Node>();

        public Lexer TokenSource {
            get {
                if (tokenSource == null) {
                    foreach (var child in children) {
                        tokenSource = child.TokenSource;
                        if (tokenSource != null) {
                            break;
                        }
                    }
                }
                return tokenSource;
            }
            set {
                tokenSource = value;
            }
        }

        public ListAdapter<Node> Children {get => new ListAdapter<Node>(children); }

        public Node GetChild(int i) {
            return children[i];
        }

        public void SetChild(int i, Node n) {
            children[i] = n;
            n.Parent = this;
        }

        public void AddChild(Node n) {
            children.Add(n);
            n.Parent = this;
        }

        public void AddChild(int i, Node n) {
            children.Insert(i, n);
            n.Parent = this;
        }

        public void ClearChildren() => children.Clear();


        public BaseNode(Lexer tokenSource) {
            this.tokenSource = tokenSource;
        }

        public void AddChild(BaseNode node) {
            AddChild(node, -1);
        }

        public void AddChild(BaseNode node, int index) {
            if (index < 0) {
                children.Add(node);
            }
            else {
                children.Insert(index, node);
            }
            node.Parent = this;
        }

        public void RemoveChild(int index) {
            children.RemoveAt(index);
        }

        public int ChildCount {
            get => children.Count;
        }
    }

    public class Token : Node {

        public Lexer TokenSource { get; set; }
        public int BeginOffset { get; set; }
        public int EndOffset { get; set; }
        public Node Parent { get; set; }
        public bool IsUnparsed { get; internal set; }
        public int ChildCount => 0;
        public Node GetChild(int i) => null;
        public ListAdapter<Node> Children => new ListAdapter<Node>();
        public void SetChild(int i, Node n) { throw new NotSupportedException(); }
        public void AddChild(Node n) { throw new NotSupportedException(); }
        public void AddChild(int i, Node n) { throw new NotSupportedException(); }
        public void RemoveChild(int i) { throw new NotSupportedException(); }
        public void ClearChildren() {}

        // TODO us default implementations in interface
        public int BeginLine {
            get {
                return (TokenSource == null) ? 0 : TokenSource.GetLineFromOffset(BeginOffset);
            }
        }

        public int EndLine {
            get {
                return (TokenSource == null) ? 0 : TokenSource.GetLineFromOffset(EndOffset - 1);
            }
        }

        public int BeginColumn {
            get {
                return (TokenSource == null) ? 0 : TokenSource.GetCodePointColumnFromOffset(BeginOffset);
            }
        }

        public int EndColumn {
            get {
                return (TokenSource == null) ? 0 : TokenSource.GetCodePointColumnFromOffset(EndOffset - 1);
            }
        }
        
        public TokenType Type { get; private set; }


        private string _image;

        public string Image {
            get {
                return _image != null ? _image: Source;
            }
            set { _image = value; }
        }

        virtual public bool IsSkipped() {
           return false;
        }

        virtual public bool IsVirtual() {
           return Type == TokenType.EOF;
        }


        /**
        * @param type the #TokenType of the token being constructed
        * @param image the String content of the token
        * @param tokenSource the object that vended this token.
        */
        public Token(TokenType kind, Lexer tokenSource, int beginOffset, int endOffset) {
            Type = kind;
            TokenSource = tokenSource;
            BeginOffset = beginOffset;
            EndOffset = endOffset;
        }


        internal Token prependedToken, appendedToken;

        internal bool isInserted;

        internal void PreInsert(Token prependedToken) {
            if (prependedToken == this.prependedToken) {
                return;
            }
            prependedToken.appendedToken = this;
            Token existingPreviousToken = this.PreviousCachedToken;
            if (existingPreviousToken != null) {
                existingPreviousToken.appendedToken = prependedToken;
                prependedToken.prependedToken = existingPreviousToken;
            }
            prependedToken.isInserted = true;
            prependedToken.BeginOffset = prependedToken.EndOffset = this.BeginOffset;
            this.prependedToken = prependedToken;
        }
        
        internal void UnsetAppendedToken() {
            appendedToken = null;
        }

        internal static Token NewToken(TokenType type, String image, Lexer tokenSource) {
            Token result = NewToken(type, tokenSource, 0, 0);
            result.Image = image;
            return result;
        }

        internal static Token NewToken(TokenType type, Lexer tokenSource, int beginOffset, int endOffset) {
            switch(type) {
            case TokenType.SPACE : return new Whitespace(TokenType.SPACE, tokenSource, beginOffset, endOffset);
            case TokenType.CONTINUE_LINE : return new Whitespace(TokenType.CONTINUE_LINE, tokenSource, beginOffset, endOffset);
            case TokenType.COMMENT : return new Comment(TokenType.COMMENT, tokenSource, beginOffset, endOffset);
            case TokenType.NEWLINE : return new Newline(TokenType.NEWLINE, tokenSource, beginOffset, endOffset);
            case TokenType.ASSIGN : return new Delimiter(TokenType.ASSIGN, tokenSource, beginOffset, endOffset);
            case TokenType.AT : return new Delimiter(TokenType.AT, tokenSource, beginOffset, endOffset);
            case TokenType.COLON : return new Delimiter(TokenType.COLON, tokenSource, beginOffset, endOffset);
            case TokenType.COMMA : return new Delimiter(TokenType.COMMA, tokenSource, beginOffset, endOffset);
            case TokenType.EQ : return new Delimiter(TokenType.EQ, tokenSource, beginOffset, endOffset);
            case TokenType.LBRACE : return new Delimiter(TokenType.LBRACE, tokenSource, beginOffset, endOffset);
            case TokenType.RBRACE : return new Delimiter(TokenType.RBRACE, tokenSource, beginOffset, endOffset);
            case TokenType.LBRACKET : return new Delimiter(TokenType.LBRACKET, tokenSource, beginOffset, endOffset);
            case TokenType.RBRACKET : return new Delimiter(TokenType.RBRACKET, tokenSource, beginOffset, endOffset);
            case TokenType.LPAREN : return new Delimiter(TokenType.LPAREN, tokenSource, beginOffset, endOffset);
            case TokenType.RPAREN : return new Delimiter(TokenType.RPAREN, tokenSource, beginOffset, endOffset);
            case TokenType.SEMICOLON : return new Delimiter(TokenType.SEMICOLON, tokenSource, beginOffset, endOffset);
            case TokenType.STAR : return new Delimiter(TokenType.STAR, tokenSource, beginOffset, endOffset);
            case TokenType.STAR_STAR : return new Delimiter(TokenType.STAR_STAR, tokenSource, beginOffset, endOffset);
            case TokenType.MINUSASSIGN : return new Delimiter(TokenType.MINUSASSIGN, tokenSource, beginOffset, endOffset);
            case TokenType.PLUSASSIGN : return new Delimiter(TokenType.PLUSASSIGN, tokenSource, beginOffset, endOffset);
            case TokenType.STARASSIGN : return new Delimiter(TokenType.STARASSIGN, tokenSource, beginOffset, endOffset);
            case TokenType.ATASSIGN : return new Delimiter(TokenType.ATASSIGN, tokenSource, beginOffset, endOffset);
            case TokenType.SLASHASSIGN : return new Delimiter(TokenType.SLASHASSIGN, tokenSource, beginOffset, endOffset);
            case TokenType.REMASSIGN : return new Delimiter(TokenType.REMASSIGN, tokenSource, beginOffset, endOffset);
            case TokenType.ANDASSIGN : return new Delimiter(TokenType.ANDASSIGN, tokenSource, beginOffset, endOffset);
            case TokenType.ORASSIGN : return new Delimiter(TokenType.ORASSIGN, tokenSource, beginOffset, endOffset);
            case TokenType.XORASSIGN : return new Delimiter(TokenType.XORASSIGN, tokenSource, beginOffset, endOffset);
            case TokenType.LSHIFTASSIGN : return new Delimiter(TokenType.LSHIFTASSIGN, tokenSource, beginOffset, endOffset);
            case TokenType.RSHIFTASSIGN : return new Delimiter(TokenType.RSHIFTASSIGN, tokenSource, beginOffset, endOffset);
            case TokenType.STARSTARASSIGN : return new Delimiter(TokenType.STARSTARASSIGN, tokenSource, beginOffset, endOffset);
            case TokenType.SLASHSLASHASSIGN : return new Delimiter(TokenType.SLASHSLASHASSIGN, tokenSource, beginOffset, endOffset);
            case TokenType.BIT_AND : return new Operator(TokenType.BIT_AND, tokenSource, beginOffset, endOffset);
            case TokenType.BIT_OR : return new Operator(TokenType.BIT_OR, tokenSource, beginOffset, endOffset);
            case TokenType.XOR : return new Operator(TokenType.XOR, tokenSource, beginOffset, endOffset);
            case TokenType.TILDE : return new Operator(TokenType.TILDE, tokenSource, beginOffset, endOffset);
            case TokenType.COLONEQUALS : return new Operator(TokenType.COLONEQUALS, tokenSource, beginOffset, endOffset);
            case TokenType.DOT : return new Operator(TokenType.DOT, tokenSource, beginOffset, endOffset);
            case TokenType.ELLIPSIS : return new Operator(TokenType.ELLIPSIS, tokenSource, beginOffset, endOffset);
            case TokenType.LE : return new Operator(TokenType.LE, tokenSource, beginOffset, endOffset);
            case TokenType.GE : return new Operator(TokenType.GE, tokenSource, beginOffset, endOffset);
            case TokenType.NE : return new Operator(TokenType.NE, tokenSource, beginOffset, endOffset);
            case TokenType.GT : return new Operator(TokenType.GT, tokenSource, beginOffset, endOffset);
            case TokenType.LT : return new Operator(TokenType.LT, tokenSource, beginOffset, endOffset);
            case TokenType.MINUS : return new Operator(TokenType.MINUS, tokenSource, beginOffset, endOffset);
            case TokenType.PLUS : return new Operator(TokenType.PLUS, tokenSource, beginOffset, endOffset);
            case TokenType.SLASH : return new Operator(TokenType.SLASH, tokenSource, beginOffset, endOffset);
            case TokenType.PERCENT : return new Operator(TokenType.PERCENT, tokenSource, beginOffset, endOffset);
            case TokenType.LSHIFT : return new Operator(TokenType.LSHIFT, tokenSource, beginOffset, endOffset);
            case TokenType.RSHIFT : return new Operator(TokenType.RSHIFT, tokenSource, beginOffset, endOffset);
            case TokenType.HOOK : return new Operator(TokenType.HOOK, tokenSource, beginOffset, endOffset);
            case TokenType.RARROW : return new Operator(TokenType.RARROW, tokenSource, beginOffset, endOffset);
            case TokenType.AND : return new Keyword(TokenType.AND, tokenSource, beginOffset, endOffset);
            case TokenType.AS : return new Keyword(TokenType.AS, tokenSource, beginOffset, endOffset);
            case TokenType._ASSERT : return new Keyword(TokenType._ASSERT, tokenSource, beginOffset, endOffset);
            case TokenType.ASYNC : return new Keyword(TokenType.ASYNC, tokenSource, beginOffset, endOffset);
            case TokenType.AWAIT : return new Keyword(TokenType.AWAIT, tokenSource, beginOffset, endOffset);
            case TokenType.BREAK : return new Keyword(TokenType.BREAK, tokenSource, beginOffset, endOffset);
            case TokenType.CASE : return new Keyword(TokenType.CASE, tokenSource, beginOffset, endOffset);
            case TokenType.CLASS : return new Keyword(TokenType.CLASS, tokenSource, beginOffset, endOffset);
            case TokenType.CONTINUE : return new Keyword(TokenType.CONTINUE, tokenSource, beginOffset, endOffset);
            case TokenType.DEF : return new Keyword(TokenType.DEF, tokenSource, beginOffset, endOffset);
            case TokenType.DEL : return new Keyword(TokenType.DEL, tokenSource, beginOffset, endOffset);
            case TokenType.EXCEPT : return new Keyword(TokenType.EXCEPT, tokenSource, beginOffset, endOffset);
            case TokenType.FINALLY : return new Keyword(TokenType.FINALLY, tokenSource, beginOffset, endOffset);
            case TokenType.FOR : return new Keyword(TokenType.FOR, tokenSource, beginOffset, endOffset);
            case TokenType.FROM : return new Keyword(TokenType.FROM, tokenSource, beginOffset, endOffset);
            case TokenType.GLOBAL : return new Keyword(TokenType.GLOBAL, tokenSource, beginOffset, endOffset);
            case TokenType.IF : return new Keyword(TokenType.IF, tokenSource, beginOffset, endOffset);
            case TokenType.IN : return new Keyword(TokenType.IN, tokenSource, beginOffset, endOffset);
            case TokenType.IS : return new Keyword(TokenType.IS, tokenSource, beginOffset, endOffset);
            case TokenType.ELIF : return new Keyword(TokenType.ELIF, tokenSource, beginOffset, endOffset);
            case TokenType.ELSE : return new Keyword(TokenType.ELSE, tokenSource, beginOffset, endOffset);
            case TokenType.FALSE : return new Keyword(TokenType.FALSE, tokenSource, beginOffset, endOffset);
            case TokenType.IMPORT : return new Keyword(TokenType.IMPORT, tokenSource, beginOffset, endOffset);
            case TokenType.LAMBDA : return new Keyword(TokenType.LAMBDA, tokenSource, beginOffset, endOffset);
            case TokenType.MATCH : return new Keyword(TokenType.MATCH, tokenSource, beginOffset, endOffset);
            case TokenType.NONLOCAL : return new Keyword(TokenType.NONLOCAL, tokenSource, beginOffset, endOffset);
            case TokenType.NONE : return new Keyword(TokenType.NONE, tokenSource, beginOffset, endOffset);
            case TokenType.NOT : return new Keyword(TokenType.NOT, tokenSource, beginOffset, endOffset);
            case TokenType.OR : return new Keyword(TokenType.OR, tokenSource, beginOffset, endOffset);
            case TokenType.PASS : return new Keyword(TokenType.PASS, tokenSource, beginOffset, endOffset);
            case TokenType.PEG_PARSER : return new Keyword(TokenType.PEG_PARSER, tokenSource, beginOffset, endOffset);
            case TokenType.RAISE : return new Keyword(TokenType.RAISE, tokenSource, beginOffset, endOffset);
            case TokenType.RETURN : return new Keyword(TokenType.RETURN, tokenSource, beginOffset, endOffset);
            case TokenType.TRUE : return new Keyword(TokenType.TRUE, tokenSource, beginOffset, endOffset);
            case TokenType.TRY : return new Keyword(TokenType.TRY, tokenSource, beginOffset, endOffset);
            case TokenType.WHILE : return new Keyword(TokenType.WHILE, tokenSource, beginOffset, endOffset);
            case TokenType.WITH : return new Keyword(TokenType.WITH, tokenSource, beginOffset, endOffset);
            case TokenType.YIELD : return new Keyword(TokenType.YIELD, tokenSource, beginOffset, endOffset);
            case TokenType.DECNUMBER : return new NumericalLiteral(TokenType.DECNUMBER, tokenSource, beginOffset, endOffset);
            case TokenType.BADDECNUMBER : return new NumericalLiteral(TokenType.BADDECNUMBER, tokenSource, beginOffset, endOffset);
            case TokenType.HEXNUMBER : return new NumericalLiteral(TokenType.HEXNUMBER, tokenSource, beginOffset, endOffset);
            case TokenType.OCTNUMBER : return new NumericalLiteral(TokenType.OCTNUMBER, tokenSource, beginOffset, endOffset);
            case TokenType.BINNUMBER : return new NumericalLiteral(TokenType.BINNUMBER, tokenSource, beginOffset, endOffset);
            case TokenType.FLOAT : return new NumericalLiteral(TokenType.FLOAT, tokenSource, beginOffset, endOffset);
            case TokenType.COMPLEX : return new NumericalLiteral(TokenType.COMPLEX, tokenSource, beginOffset, endOffset);
            case TokenType.STRING_LITERAL : return new StringLiteral(TokenType.STRING_LITERAL, tokenSource, beginOffset, endOffset);
            case TokenType.NAME : return new Name(TokenType.NAME, tokenSource, beginOffset, endOffset);
            case TokenType.BADNAME : return new BADNAME(TokenType.BADNAME, tokenSource, beginOffset, endOffset);
            case TokenType.INDENT : return new IndentToken(TokenType.INDENT, tokenSource, beginOffset, endOffset);
            case TokenType.DEDENT : return new DedentToken(TokenType.DEDENT, tokenSource, beginOffset, endOffset);
            case TokenType.INVALID : return new InvalidToken(tokenSource, beginOffset, endOffset);
            default : return new Token(type, tokenSource, beginOffset, endOffset);
            }
        }

        internal string NormalizedText => (Type == TokenType.EOF) ? "EOF" : Image;

        internal Token NextToken { get; set; }
        internal string Location {
            get {
                Node n = (Node) this;

                return $"{TokenSource.InputSource}:{n.BeginLine}:{n.BeginColumn}";
            }
        }

        // Copy the location info from another node or start/end nodes
        internal void CopyLocationInfo(Node start, Node end = null) {
            ((Node) this).CopyLocationInfo(start, end);
            if (start is Token otherTok) {
                appendedToken = otherTok.appendedToken;
                prependedToken = otherTok.prependedToken;
            }
            if (end != null) {
                if (end is Token endToken) {
                    appendedToken = endToken.appendedToken;
                }
            }
        }
        internal Token Next {
            get {
                return NextParsedToken;
            }
        }

        internal Token NextParsedToken {
            get {
                var result = NextCachedToken;
                while ((result != null) && result.IsUnparsed) {
                    result = result.NextCachedToken;
                }
                return result;
            }
        }

        internal Token NextCachedToken {
            get {
                if (appendedToken != null) {
                    return appendedToken;
                }
                return TokenSource == null ? null : TokenSource.NextCachedToken(EndOffset);
            }
        }

        internal Token PreviousCachedToken {
            get {
                if (prependedToken !=null) {
                    return prependedToken;
                }
                return TokenSource == null ? null : TokenSource.PreviousCachedToken(BeginOffset);
            }
        }

        internal Token PreviousToken {
            get {
                return PreviousCachedToken;
            }
        }

        internal Token ReplaceType(TokenType type) {
            Token result = NewToken(Type, TokenSource, BeginOffset, EndOffset);
            result.prependedToken = prependedToken;
            result.appendedToken = appendedToken;
            result.isInserted = isInserted;
            if (result.appendedToken != null) {
                result.appendedToken.prependedToken = result;
            }
            if (result.prependedToken != null) {
                result.prependedToken.appendedToken = result;
            }
            if (!result.isInserted) {
                TokenSource.CacheToken(result);
            }
            return result;
        }

        public string Source {
            get {
                if (Type == TokenType.EOF) {
                    return "";
                }
                return (TokenSource == null) ? null : TokenSource.GetText(BeginOffset, EndOffset);
            }
        }

        private IEnumerable<Token> precedingTokens() {
            Token current = this;
            Token t;

            while ((t = current.PreviousCachedToken) != null) {
                current = t;
                yield return current;
            }
        }

        internal Iterator<Token> PrecedingTokens() {
            return new GenWrapper<Token>(precedingTokens());
        }




        virtual public ListAdapter<int> GetIndents() {
            return null;
        }

        internal bool StartsLine() {
            Iterator<Token> toks = PrecedingTokens();
            while (toks.HasNext()) {
                Token t = toks.Next();
                if (t.Type == TokenType.CONTINUE_LINE) {
                    return false;
                }
                if ((!t.IsUnparsed)) {
                    return t.EndLine != this.BeginLine;
                }
            }
            return true;
        }

        public Token GetPreviousToken() {
            return PreviousCachedToken;
        }

        public void SetImage(String image) {
            this.Image = Image;
        }



    }

    // Token subclasses

    public class Operator : Token {
        public Operator(TokenType kind, Lexer tokenSource, int beginOffset, int endOffset) : base(kind, tokenSource, beginOffset, endOffset) {}
    }

    public class Comment : Token {
        public Comment(TokenType kind, Lexer tokenSource, int beginOffset, int endOffset) : base(kind, tokenSource, beginOffset, endOffset) {}
    }

    public class Delimiter : Token {
        public Delimiter(TokenType kind, Lexer tokenSource, int beginOffset, int endOffset) : base(kind, tokenSource, beginOffset, endOffset) {}
    }

    public class Keyword : Token {
        public Keyword(TokenType kind, Lexer tokenSource, int beginOffset, int endOffset) : base(kind, tokenSource, beginOffset, endOffset) {}
    }

    public class StringLiteral : Token {
        public StringLiteral(TokenType kind, Lexer tokenSource, int beginOffset, int endOffset) : base(kind, tokenSource, beginOffset, endOffset) {}
    }

    public class BADNAME : Token {
        public BADNAME(TokenType kind, Lexer tokenSource, int beginOffset, int endOffset) : base(kind, tokenSource, beginOffset, endOffset) {}
    }

    public class NumericalLiteral : Token {
        public NumericalLiteral(TokenType kind, Lexer tokenSource, int beginOffset, int endOffset) : base(kind, tokenSource, beginOffset, endOffset) {}
    }

    public class Newline : Token {
        public Newline(TokenType kind, Lexer tokenSource, int beginOffset, int endOffset) : base(kind, tokenSource, beginOffset, endOffset) {}
    }

    public class Whitespace : Token {
        public Whitespace(TokenType kind, Lexer tokenSource, int beginOffset, int endOffset) : base(kind, tokenSource, beginOffset, endOffset) {}
    }

    public class Name : Token {
        public Name(TokenType kind, Lexer tokenSource, int beginOffset, int endOffset) : base(kind, tokenSource, beginOffset, endOffset) {}
    }


    public class IndentToken : Token {
        public IndentToken(TokenType kind, Lexer tokenSource, int beginOffset, int endOffset) : base(kind, tokenSource, beginOffset, endOffset) {}

        private ListAdapter<int> indents;

        public static Token MakeIndentToken(Token followingToken, Lexer tokenSource, ListAdapter<int> indents) {
            IndentToken result = new IndentToken(TokenType.INDENT, tokenSource, 0, 0);
            result.indents = new ListAdapter<int>(indents.Count);
            result.indents.AddRange(indents);
            followingToken.PreInsert(result);
            return result;
        }

        override public ListAdapter<int> GetIndents() {
            return new ListAdapter<int>(indents);
        }

        override public bool IsVirtual() {
            return true;
        }

        public int GetIndentAmount() {
            return indents[indents.Count - 1] - indents[indents.Count - 2];
        }


    }

    public class DedentToken : Token {
        public DedentToken(TokenType kind, Lexer tokenSource, int beginOffset, int endOffset) : base(kind, tokenSource, beginOffset, endOffset) {}

        private ListAdapter<int> indents;
        private int dedentAmount;

        public static Token MakeDedentToken(Token followingToken, Lexer tokenSource, ListAdapter<int> indents, int dedentAmount) {
            DedentToken result = new DedentToken(TokenType.DEDENT, tokenSource, 0, 0);
            result.indents = new ListAdapter<int>(indents.Count);
            result.indents.AddRange(indents);
            result.dedentAmount = dedentAmount;
            followingToken.PreInsert(result);
            return result;
        }

        override public ListAdapter<int> GetIndents() {
            return new ListAdapter<int>(indents);
        }

        override public bool IsVirtual() {
            return true;
        }

        public int GetDedentAmount() {
            return dedentAmount;
        }


    }



    public class InvalidToken : Token {
        public InvalidToken(Lexer tokenSource, int beginOffset, int endOffset) : base(TokenType.INVALID, tokenSource, beginOffset, endOffset) {}
    }
}
